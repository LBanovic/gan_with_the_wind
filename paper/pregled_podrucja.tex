\chapter{Pregled područja}
Iako su generativne suparničke mreže nov koncept, atraktivno su područje istraživanja te su pokazale velik uspjeh u generiranju slika i povezanim zadatcima. Međutim, postoji značajan prostor za napredak. S jedne strane, istraživanje je usredotočeno na generiranje realističnih slika visoke rezolucije. Prepreke na koje nailaze istraživači su, između ostaloga, rast broja parametara generatora i diskriminatora kako raste rezolucija što znatno produljuje i na trajanje treniranja modela. Osim toga, čak i ako je model uspješan u generiranju realističnih slika, događa se da ipak ne uspijeva generirati različite varijacije koje se mogu pronaći unutar skupa za treniranje. Tada možemo naići na dvije situacije: \textit{mode collapse} i \textit{mode dropping}. \textit{Mode collapse} je situacija u kojoj model ne uspijeva generirati dovoljno raznovrsne primjere neke grupe. Primjerice, ako temeljem učenja na skupu slika trokuta nauči generirati samo jednakostranične trokute. \textit{Mode dropping} je, pak, situacija gdje generator uopće ne generira primjere iz nekih od grupa. Ako se vratimo na analogiju s geometrijskim likovima, model gdje se dogodio \textit{mode dropping}, ako je treniran na slikama trokuta i kvadrata, naučio bi generirati samo kvadrate. Ovo je tipična situacija kada se pri treniranju koriste skupovi podataka koji sadrže primjere različitih klasa, kao što je CIFAR-10.

Druga grana istraživanja bavi se dvama problemima:
\begin{itemize}
	\item stabilnost treniranja generativnih suparničkih mreža
	\item međusobna usporedba modela
\end{itemize}
Naime, treniranje generativnih suparničkih mreža uistinu je izazov. Poznato je da su duboki modeli osjetljivi na promjene hiperparametara kao što je stopa učenja, što ovdje posebno dolazi do izražaja s dva duboka modela koji su međusobno povezani. Osim toga, bitan je i način na koji su inicijalizirane težine na početku treniranja, kao i skup podataka na kojima su trenirani te, naravno, sama arhitektura modela. Ovi faktori, uz dugo trajanje optimizacijskog postupka, otežavaju pronalaženje optimalne konfiguracije modela za zadani problem. Nadalje, poseban je izazov i usporedba različitih vrsta generativnih suparničkih mreža. Dva su razloga - nasumičnost prisutna tijekom optimizacije bitna je prepreka ponavljanju ranije dobivenih rezultata za neku mrežu te ne postoji dobra metrika kojom možemo usporediti generirane slike. Cilj je dobiti slike koje su ljudima realistične, ali kako koncept "realističnosti" kvantificirati?

U nastavku ovoga poglavlja, predstavit ćemo strategije i trikove koji su češće primijenjivani, a razvijeni su kao odgovori na ove izazove. Predstavit ćemo uobičajene funkcije pogreške, metrike za vrednovanje modela, regularizacijske tehnike i arhitekture.

\section{Vrednovanje modela}
\subsection{Vrijednost \textit{Inception}}
Vrijednost \textit{Inception} \engl{Inception Score, IS} \citep{salimans2016improved} mjera je kojom pokušavamo kvantificirati povoljne karakteristike kod generativnih suparničkih mreža: realističnost izgleda slika i raznovrsnost. Osnovna je ideja korištenje klasifikatora da bi se klasificirale generirane slike. Uobičajeno, izlaz klasifikatora je vektor koji sadrži vjerojatnosti pripadanja promatranog primjera $\vec{x}$ svakoj od klasa, što možemo označiti s $p(y|\vec{x})$. Ako generator generira slike koje odgovaraju ulaznoj distribuciji, očekujemo da će ih klasifikator s visokom pouzdanošću svrstati u odgovarajuću klasu, odnosno entropija distribucije $p(y|\vec{x})$ za neki $\vec{x} = G(\vec{z})$ bit će niska. S druge strane, ako generator uspijeva u sintezi raznovrsnih slika, razdioba $p(y) = \int_{\vec{z}}p(y|\vec{x} = G(\vec{z})dz$ imat će visoku entropiju. Napokon, da bi se kombinirali ovi zahtjevi, autori predlažu sljedeći izraz:
\begin{equation}
	\operatorname*{IS} = \exp(\mathbb{E}_{\vec{z}} \left[D_{KL}(p(y|G(\vec{z}))\|p(y))\right])
\end{equation}
Ovdje se eksponencijalna funkcija koristi samo da bi rezultati bili lakše usporedivi, a ime je dobila po modelu \textit{Inception} koji se koristi kao klasifikator. Problem kod ovakve formulacije je što zapravo to nije mjera udaljenosti, jer ne zadovoljava nejednakost trokuta. Osim toga, ne uzima u obzir ni apriornu razdiobu oznaka - ako ulazni skup ima 40\% primjera jedne klase i 60\% druge, očekujemo da će dobro naučen generator imati sličnu distribuciju oznaka, ali ova mjera nam ne daje takvu garanciju. 

\subsection{Fréchetova \textit{Inception} udaljenost}
Fréchetova \textit{Inception} udaljenost \citep{heusel2017gans} \engl{Fréchet Inception Distance, FID} široko je prihvaćena metrika za evaluaciju performansi generativnoga modela. Ideja je da pretpostavimo da su $p_{model}$ i $p_{\mathcal{D}}$ multivarijatne Gaussove razdiobe te odredimo Fréchetovu udaljenost između njih. Da bismo odredili parametre razdioba, prvo generirane i stvarne slike predstavimo kao vektore značajki. Te vektore dobivamo kao izlaz posebnog sloja mreže \textit{InceptionNet}, po čemu je i metrika dobila ime. Nakon što procijenimo očekivanje i kovarijancu razdioba (radi jednostavnosti, označimo razdiobe s $p$ i $q$), FID računamo kao:
\begin{equation}
\operatorname*{FID}(p, q) = \|\vec{\mu}_p - \vec{\mu}_q\|^2 + \operatorname*{Tr}(\Sigma_p + \Sigma_q - 2\sqrt{\Sigma_p\Sigma_q})
\end{equation}
Operator Tr označava trag matrice (sumu elemenata na glavnoj dijagonali).
Povoljne karakteristike ove metrike su:
\begin{itemize}
	\item ako se dogodi \textit{mode collapse}, generator će imati loš FID rezultat
	\item osjetljiva je na kvalitetu generiranih slika
\end{itemize}
Osim toga, autori tvrde da je konzistentna s ljudskom ocjenom te da je otpornija na šum od IS-a. Iz tog razloga upravo to je metrika koja se u praksi koristi za evaluaciju.

\subsection{Preciznost i odziv}
\citep{lucic2017gans} predlažu da se za ocjenu modela koriste preciznost i odziv. Preciznost i odziv metrike su koje se često koriste u klasifikacijskim problemima, a kvantificiraju neke poželjne karakteristike klasifikatora. Konkretno, klasifikator visoke preciznosti ima mali broj lažno pozitivnih uzoraka, dok visok odziv znači da je uspio ispravno označiti gotovo sve pozitivno označene uzorke. Očigledno, za ovakav problem potrebne su nam oznake primjera s kojima često ne raspolažemo kod generiranja slika. No, možemo ih aproksimirati.
Autori predlažu treniranje generativnoga modela na skupu konveksnih poligona. Pokazali su da se na efikasan način može odrediti udaljenost generirane slike od najbližeg elementa iz takvog skupa. Temeljem dobivene udaljenosti, procjenjujemo preciznost i odziv. U našem slučaju, preciznost bi bila visoka ako je prosječna udaljenost niska, dok je odziv visok ako generator uspijeva generirati sliku blizu bilo kojem primjeru u skupu. Tako preciznost modelira kvalitetu generiranih slika, a odziv raznovrsnost.   
   
   

Problem kod prethodno navedenih metrika je što pomoću njih ne možemo prepoznati prenaučenost modela. Pogledamo li izraze za njihov izračun, možemo primijetiti da će model koji bi zapamtio sve podatke iz skupa za treniranje imati izvrsne vrijednosti neovisno koju metriku izaberemo. Problem nije jednostavan, jer je pretpostavka da skupovi podataka za učenje i ispitivanje prate istu razdiobu te niti jedna metrika koja ocjenjuje razliku između razdioba neće uspjeti u detekciji prenaučenosti.
   